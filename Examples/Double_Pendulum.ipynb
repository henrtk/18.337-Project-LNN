{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6baf6ea-df10-49fd-bee8-fb087be2129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DifferentialEquations, Flux, Zygote, LinearAlgebra, ForwardDiff, FiniteDiff, Distributions, Plots, Random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c04cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LNNProject\n",
    "Threads.nthreads()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f1dc58",
   "metadata": {},
   "source": [
    "## Demonstration of the framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e5d820-6dc9-46d8-a7c8-87e61f8fb102",
   "metadata": {},
   "source": [
    "## Analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a27dc-3f08-4ec0-be29-951e3e7e3f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "function analytical_RHS(du, u, temp, t=0)\n",
    "    t1, t2, w1, w2 = u[1], u[2], u[3], u[4]\n",
    "    m1, m2, l1, l2, g = (1, 1, 1, 1, 9.81)\n",
    "    a1 = (l2 / l1) * (m2 / (m1 + m2)) * cos(t1 - t2)\n",
    "    a2 = (l1 / l2) * cos(t1 - t2)\n",
    "    f1 = -(l2 / l1) * (m2 / (m1 + m2)) * (w2^2) * sin(t1 - t2) - (g / l1) * sin(t1)\n",
    "    f2 = (l1 / l2) * (w1^2) * sin(t1 - t2) - (g / l2) * sin(t2)\n",
    "    g1 = (f1 - a1 * f2) / (1 - a1 * a2)\n",
    "    g2 = (f2 - a2 * f1) / (1 - a1 * a2)\n",
    "    du .= [w1, w2, g1, g2]\n",
    "end\n",
    "function analytical_Lagrangian(x)\n",
    "    m1, m2, l1, l2, g = (1,1,1,1,9.81)\n",
    "    θ1, θ2, v1, v2 = x[1], x[2], x[3], x[4]\n",
    "    term1 = 0.5*(m1+m2)*l1^2*v1^2\n",
    "    term2 = 0.5*m2*l2^2*v2^2\n",
    "    term3 = m2*l1*l2*v1*v2*cos(θ1-θ2)\n",
    "    term4 = (m1+m2)*g*l1*cos(θ1)\n",
    "    term5 = m2*g*l2*cos(θ2)\n",
    "    return term1 + term2 + term3 + term4 + term5\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f5c3c-5229-4ea5-a122-475d5823e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function energy(q, q_dot, m1, m2, l1, l2, g)\n",
    "  t1, t2 = q     # theta 1 and theta 2\n",
    "  w1, w2 = q_dot # omega 1 and omega 2\n",
    "\n",
    "  # kinetic energy (T)\n",
    "  T1 = 0.5 * m1 * (l1 * w1)^2\n",
    "  T2 = 0.5 * m2 * ((l1 * w1)^2 + (l2 * w2)^2 +\n",
    "                    2 * l1 * l2 * w1 * w2 * jnp.cos(t1 - t2))\n",
    "  T = T1 + T2\n",
    "  \n",
    "  # potential energy (V)\n",
    "  y1 = -l1 * jnp.cos(t1)\n",
    "  y2 = y1 - l2 * jnp.cos(t2)\n",
    "  V = m1 * g * y1 + m2 * g * y2\n",
    "\n",
    "  return T + V\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d8554-fdf5-4bb2-a126-1de4b12e1676",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L = & \\frac{1}{2}(m_1 + m_2) l_1^2 \\dot{\\theta}_1^2 +\n",
    "\t\\frac{1}{2}m_2 l_2^2 \\dot{\\theta}_2^2 + m_2l_1l_2\\dot{\\theta}_1\\dot{\\theta}_2\n",
    "\t\\cos(\\theta_1 - \\theta_2)\\nonumber\\\\[3pt]\n",
    "     &+ (m_1 + m_2) g l_1 \\cos\\theta_1 + m_2 g l_2\\cos\\theta_2\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9face597-da52-4439-bb0a-89a62b4f0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function analytical_sol(x_0, saveat)\n",
    "    prob = ODEProblem(analytical_RHS, x_0, (0.0, saveat[end]), [0.], saveat=saveat)\n",
    "    sol = solve(prob, Tsit5())\n",
    "    data = sol.u'\n",
    "    return saveat, data\n",
    "end\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b87918f-6bb0-4fd6-9872-c7f6e6aa8870",
   "metadata": {},
   "source": [
    "## Demonstration of our code\n",
    "### First generate LNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9579791-1418-497b-a359-5aa812781aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Dense(4, 16, softplus),        \n",
    "    Dense(16, 4, sigmoid), \n",
    "    Dense(4,1)\n",
    ")\n",
    "p, res = Flux.destructure(model)\n",
    "\n",
    "LNN = NeuralLagrangian(model, [0.0, 0.1], saveat=0:0.01:0.10, dt = 0.001, adaptive = false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run precompiles the derivatives... Sloooow. Maybe add a single run to object generation?\n",
    "LNN([Float32(0.1), Float32(0.1), Float32(0.0), Float32(0.0)], Euler(), p)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e84b328",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be91035-8254-4cee-a302-f3e0520d337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function cost(p, x_0)\n",
    "    sol = LNN(x_0, Heun(), p)\n",
    "    L_dat = sol.u'\n",
    "    ts, true_dat = analytical_sol(x_0, LNN.kwargs[:saveat])\n",
    "    return norm(L_dat .- true_dat,2) + 0.1*norm(p,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925a90a-84e1-4e4c-bb71-cd93b7d2cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(0.001)\n",
    "#sol = LNN(x_0, Euler(), p)\n",
    "Epochs = 10\n",
    "lossvec = zeros(Epochs)\n",
    "threshold = 4\n",
    "\n",
    "batch_size = 11\n",
    "grads = Vector(undef, batch_size)\n",
    "# Generate random initial conditions between -pi and pi\n",
    "\n",
    "for i in 1:Epochs\n",
    "    x_0s = [0.5*pi.-rand(Float32, 4).*pi/2 for j in 1:batch_size]\n",
    "    \n",
    "    Threads.@threads for j in 1:batch_size\n",
    "        grads[j] = FiniteDiff.finite_difference_gradient((p) -> cost(p, x_0s[j]), p)\n",
    "    end\n",
    "\n",
    "    avg_grad = sum(grads)/batch_size\n",
    "    norm_grad = norm(avg_grad, 2)\n",
    "    if norm_grad > threshold\n",
    "        @show norm_grad\n",
    "        avg_grad = threshold.*avg_grad./norm_grad\n",
    "    end\n",
    "    old_p = deepcopy(p)\n",
    "    Flux.update!(opt, p, avg_grad)\n",
    "    @show cost(p, x_0s[1])\n",
    "    lossvec[i] = cost(p, x_0s[1])\n",
    "end\n",
    "ts, true_dat = analytical_sol(x_0, LNN.kwargs[:saveat])\n",
    "\n",
    "\n",
    "lastsol = LNN(x_0, RK4(), p)\n",
    "#plot(lastsol, label=\"Learned\")\n",
    "\n",
    "\n",
    "prob = ODEProblem(analytical_RHS, x_0, (0.0, 0.1), 0, saveat=LNN.kwargs[:saveat])\n",
    "sol_analytical = solve(prob, Tsit5())\n",
    "data = sol_analytical.u\n",
    "plot(sol_analytical, label=\"Analytical\", color=\"black\")\n",
    "plot!(lastsol, label=\"Learned\", color = \"red\")\n",
    "\n",
    "# ts, dat = anal_sol(x_0)\n",
    "#display(plot(ts, L_dat, label=label=[raw\"$\\theta_1$\" raw\"$\\theta_2$\" raw\"$\\dot{\\theta_1}$\" raw\"$\\dot{\\theta_2}$\" ], \n",
    " #       xlabel=raw\"$t$\", title=\"After training\"))\n",
    "#plot(ts, dat, label=[raw\"$\\theta_1^a$\" raw\"$\\theta_2^a$\" raw\"$\\dot{\\theta_1^a}$\" raw\"$\\dot{\\theta_2^a}$\" ])\n",
    "#pltt = plot!(ts, L_dat, title=\"Comparison of learned and analytical solution\", label=[raw\"$\\theta_1^L$\" raw\"$\\theta_2^L$\" raw\"$\\dot{\\theta_1^L}$\" raw\"$\\dot{\\theta_2^L}$\" ],\n",
    "#xlabel=raw\"$t$\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
